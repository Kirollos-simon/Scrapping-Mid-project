{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2bb96ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "file_path = r\"C:\\Users\\simonk03\\Downloads\\Mid Project\\Final\\Provision2024.xlsx\"  \n",
    "if os.path.exists(file_path):  # Check if the file exists\n",
    "    excel_data = pd.ExcelFile(file_path)  # Load the Excel file\n",
    "    actual_potential = excel_data.parse(\"Actual&Potential\")  # Load 'Actual&Potential' sheet\n",
    "    loss_tree = excel_data.parse(\"Loss Tree\")  # Load 'Loss Tree' sheet\n",
    "    print(\"File loaded successfully!\")  # Confirm successful loading\n",
    "else:\n",
    "    print(f\"File not found at {file_path}. Please check the path and try again.\")  #if file is not found|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029c59f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1203 entries, 0 to 1202\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Segment           10 non-null     object \n",
      " 1   Plant             1203 non-null   object \n",
      " 2   Product           1182 non-null   object \n",
      " 3   Quantity          918 non-null    object \n",
      " 4   Risk Level        1193 non-null   object \n",
      " 5   Segement          1193 non-null   object \n",
      " 6   Code              1190 non-null   object \n",
      " 7   UOM               1193 non-null   object \n",
      " 8   Status            1193 non-null   object \n",
      " 9   Classification    1193 non-null   object \n",
      " 10  Level 1           1187 non-null   object \n",
      " 11  Level 2           1187 non-null   object \n",
      " 12  Level 3           1187 non-null   object \n",
      " 13  Scrapping Status  1193 non-null   object \n",
      " 14  Scrapping Month   1193 non-null   float64\n",
      " 15  Value in EGP      1192 non-null   float64\n",
      " 16  Date              10 non-null     object \n",
      "dtypes: float64(2), object(15)\n",
      "memory usage: 159.9+ KB\n"
     ]
    }
   ],
   "source": [
    "actual_potential.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faea9687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 28 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   Level 1                                    26 non-null     object \n",
      " 1   Product_Damaged                            10 non-null     object \n",
      " 2   Product_Expired                            8 non-null      object \n",
      " 3   Product_Not_Meeting_with_Specs_to_Be_Sold  8 non-null      object \n",
      " 4   Missing_Product                            9 non-null      object \n",
      " 5   Cancelled_NPI                              5 non-null      object \n",
      " 6   Quality_Issue                              10 non-null     object \n",
      " 7   Delisted_SKU                               15 non-null     object \n",
      " 8   Postponed_NPI                              7 non-null      object \n",
      " 9   Unnamed: 9                                 1 non-null      object \n",
      " 10  Unnamed: 10                                4 non-null      object \n",
      " 11  Unnamed: 11                                7 non-null      object \n",
      " 12  Unnamed: 12                                6 non-null      object \n",
      " 13  Unnamed: 13                                1 non-null      object \n",
      " 14  Unnamed: 14                                3 non-null      object \n",
      " 15  Unnamed: 15                                4 non-null      object \n",
      " 16  Unnamed: 16                                4 non-null      object \n",
      " 17  Unnamed: 17                                1 non-null      object \n",
      " 18  Unnamed: 18                                1 non-null      object \n",
      " 19  Unnamed: 19                                1 non-null      object \n",
      " 20  Unnamed: 20                                1 non-null      object \n",
      " 21  Unnamed: 21                                3 non-null      object \n",
      " 22  Unnamed: 22                                4 non-null      object \n",
      " 23  Unnamed: 23                                1 non-null      object \n",
      " 24  Category                                   0 non-null      float64\n",
      " 25  Category.1                                 0 non-null      float64\n",
      " 26  Irrelevant Column                          26 non-null     object \n",
      " 27  Loss Amount                                10 non-null     float64\n",
      "dtypes: float64(3), object(25)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "loss_tree.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f95e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Missing values handled in 'Actual&Potential'.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Handle Missing Values in \"Actual&Potential\"\n",
    "actual_potential['Product'].fillna('Unknown', inplace=True) # Fill missing 'Product' with 'Unknown'\n",
    "actual_potential['Risk Level'].fillna('Unknown', inplace=True) # Fill missing 'Risk Level' with 'Unknown'\n",
    "actual_potential['Quantity'] = pd.to_numeric(actual_potential['Quantity'], errors='coerce') # Convert 'Quantity' to numeric\n",
    "actual_potential['Quantity'].fillna(actual_potential['Quantity'].mean(), inplace=True) # Fill NaN 'Quantity' with the mean value\n",
    "print(\"Step 1: Missing values handled in 'Actual&Potential'.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1dceeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sub-Category' column not found in 'Loss Tree'.\n",
      "Missing values handled in 'Loss Tree'.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Handle Missing Values in \"Loss Tree\"\n",
    "\n",
    "# Check if the 'Category' column exists in the DataFrame\n",
    "if 'Category' in loss_tree.columns:\n",
    "    # Convert 'Category' to string type and fill missing values with 'Unknown'\n",
    "    loss_tree['Category'] = loss_tree['Category'].astype(str)\n",
    "    loss_tree['Category'].fillna('Unknown', inplace=True)\n",
    "else:\n",
    "    # Log a message if 'Category' column is not found\n",
    "    print(\"'Category' column not found in 'Loss Tree'.\")\n",
    "\n",
    "# Check if the 'Sub-Category' column exists in the DataFrame\n",
    "if 'Sub-Category' in loss_tree.columns:\n",
    "    # Convert 'Sub-Category' to string type and fill missing values with 'Unknown'\n",
    "    loss_tree['Sub-Category'] = loss_tree['Sub-Category'].astype(str)\n",
    "    loss_tree['Sub-Category'].fillna('Unknown', inplace=True)\n",
    "else:\n",
    "    # Log a message if 'Sub-Category' column is not found\n",
    "    print(\"'Sub-Category' column not found in 'Loss Tree'.\")\n",
    "\n",
    "# Log the completion of missing value handling\n",
    "print(\"Missing values handled in 'Loss Tree'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57aaf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed in 'Actual&Potential'.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Handle Duplicates in \"Actual&Potential\"\n",
    "# Removing rows that have the same 'Product', 'Risk Level', and 'Quantity'\n",
    "# We'll keep the first occurrence and drop others\n",
    "actual_potential.drop_duplicates(subset=['Product', 'Risk Level', 'Quantity'], keep='first', inplace=True)\n",
    "print(\"Duplicates removed in 'Actual&Potential'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d295268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types fixed in 'Actual&Potential'.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Handle Inconsistent Data Types in \"Actual&Potential\"\n",
    "# Convert 'Quantity' column to numeric, invalid values will be set as NaN\n",
    "actual_potential['Quantity'] = pd.to_numeric(actual_potential['Quantity'], errors='coerce')\n",
    "# Convert 'Product' to string type (even if it's already a string, this ensures consistency)\n",
    "actual_potential['Product'] = actual_potential['Product'].astype(str)\n",
    "print(\"Data types fixed in 'Actual&Potential'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07456eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misplaced rows removed in 'Actual&Potential'.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Handle Misplaced Rows/Irrelevant Data in \"Actual&Potential\"\n",
    "# Remove rows where 'Segment' is '---' and 'Plant' is '###'\n",
    "actual_potential = actual_potential[actual_potential['Segment'] != '---']\n",
    "actual_potential = actual_potential[actual_potential['Plant'] != '###']\n",
    "print(\"Misplaced rows removed in 'Actual&Potential'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8712ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers handled in 'Actual&Potential'.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Handle Outliers in \"Actual&Potential\"\n",
    "# Replace extreme values (above 1000) with NaN and then fill with the column mean\n",
    "actual_potential['Quantity'] = actual_potential['Quantity'].apply(lambda x: x if x < 1000 else np.nan)\n",
    "actual_potential['Quantity'].fillna(actual_potential['Quantity'].mean(), inplace=True)\n",
    "print(\"Outliers handled in 'Actual&Potential'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5b29649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date formats corrected in 'Actual&Potential'.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Handle Incorrect Date Formats in \"Actual&Potential\"\n",
    "# Convert 'Date' column to datetime, replacing invalid formats with NaT\n",
    "actual_potential['Date'] = pd.to_datetime(actual_potential['Date'], errors='coerce')\n",
    "\n",
    "# Fill missing date values with a default date\n",
    "actual_potential['Date'].fillna('2024-01-01', inplace=True)\n",
    "print(\"Date formats corrected in 'Actual&Potential'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "416b1c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid column headers resolved in 'Actual&Potential'.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Handle Invalid Column Headers in \"Actual&Potential\" & Remove duplicated column names\n",
    "actual_potential = actual_potential.loc[:, ~actual_potential.columns.duplicated()]\n",
    "print(\"Invalid column headers resolved in 'Actual&Potential'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0303dca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled in 'Loss Tree'.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Handle Loss Tree Specific Errors & Handle Missing Values in \"Loss Tree\"\n",
    "loss_tree['Category'] = loss_tree.get('Category', pd.Series('Unknown', index=loss_tree.index)).fillna('Unknown')\n",
    "loss_tree['Sub-Category'] = loss_tree.get('Sub-Category', pd.Series('Unknown', index=loss_tree.index)).fillna('Unknown')\n",
    "print(\"Missing values handled in 'Loss Tree'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46f2fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to 'C:\\Users\\simonk03\\Documents\\cleaned_scrapping_provision_from_modified1.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Save the cleaned data to a new Excel file\n",
    "output_path = r'C:\\Users\\simonk03\\Documents\\cleaned_scrapping_provision_from_modified1.xlsx'  # Changed path\n",
    "try:\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        actual_potential.to_excel(writer, index=False, sheet_name=\"Actual&Potential\")\n",
    "        loss_tree.to_excel(writer, index=False, sheet_name=\"Loss Tree\")\n",
    "    print(f\"Data cleaned and saved to '{output_path}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fddefa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Month format changed to 'Month Year'.\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Scrapping Month' to numeric, remove out-of-bounds values, and convert to datetime\n",
    "actual_potential['Scrapping Month'] = pd.to_datetime(\n",
    "    pd.to_numeric(actual_potential['Scrapping Month'], errors='coerce').clip(lower=1), \n",
    "    origin='unix', unit='D', errors='coerce').dt.strftime('%B %Y')\n",
    "\n",
    "print(\"Scrapping Month format changed to 'Month Year'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "721eb8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to 'C:\\Users\\simonk03\\Documents\\cleaned_scrapping_provision_from_modified1.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Save the cleaned data to a new Excel file\n",
    "output_path = r'C:\\Users\\simonk03\\Documents\\cleaned_scrapping_provision_from_modified1.xlsx'  # Changed path\n",
    "try:\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        actual_potential.to_excel(writer, index=False, sheet_name=\"Actual&Potential\")\n",
    "        loss_tree.to_excel(writer, index=False, sheet_name=\"Loss Tree\")\n",
    "    print(f\"Data cleaned and saved to '{output_path}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63afd583",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actual_potential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the data as a CSV file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msimonk03\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - Heineken International\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData siense\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMaster Data sciense\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPowerBI Projects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMid project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFinaalsss\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMid project Scrapping\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcleaned_scrapping_provision_from_modified1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m actual_potential\u001b[38;5;241m.\u001b[39mto_csv(csv_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData successfully saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'actual_potential' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the data as a CSV file\n",
    "csv_file_path = r'C:\\Users\\simonk03\\OneDrive - Heineken International\\Data siense\\Master Data sciense\\PowerBI Projects\\Mid project\\Finaalsss\\Mid project Scrapping\\cleaned_scrapping_provision_from_modified1.csv'\n",
    "actual_potential.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e3e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
